{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vdgdb-Dw101p",
    "outputId": "0835fd3a-3eeb-4707-f470-80c42f73c7ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 2 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 2 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 2 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "Rate limit exceeded. Retrying in 1 second(s)...\n",
      "F1 Score: 0.5936\n",
      "Precision: 0.6806\n",
      "Recall: 0.6197\n",
      "Accuracy: 0.6197\n",
      "Annotation complete. Results saved to annotated_sentences.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "import time\n",
    "from typing import List, Dict\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from config import API_KEY\n",
    "\n",
    "\n",
    "API_KEY = API_KEY   # it's redundant, i know\n",
    "URL = \"https://api.together.xyz/v1/chat/completions\"\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "    \"accept\": \"application/json\",\n",
    "    \"content-type\": \"application/json\"\n",
    "}\n",
    "\n",
    "def clean_bom(column_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove BOM (Byte Order Mark) from column names if present.\n",
    "    \"\"\"\n",
    "    return column_name.replace('\\ufeff', '').strip()\n",
    "\n",
    "def read_sentences_from_csv(file_path: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Reads sentences from the CSV and returns a list of dictionaries containing sentence, year, and label.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    try:\n",
    "        with open(file_path, mode='r', newline='', encoding='utf-8') as file:\n",
    "            reader = csv.DictReader(file)\n",
    "            # Clean BOM from fieldnames\n",
    "            reader.fieldnames = [clean_bom(field) for field in reader.fieldnames]\n",
    "            # print(\"CSV Column Names (after cleaning):\", reader.fieldnames)  # Print the column names to verify\n",
    "            for row in reader:\n",
    "                # Each row is a dictionary with keys corresponding to the CSV column names\n",
    "                if row:  # Ensure the row is not empty\n",
    "                    data.append({\n",
    "                        'sentence': row['sentence'].strip(),  # Now the BOM is removed\n",
    "                        'year': row['year'].strip(),\n",
    "                        'label': int(row['label'].strip())  # Assuming the label is an integer\n",
    "                    })\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {file_path} not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "    return data\n",
    "\n",
    "def annotate_sentence(sentence: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Sends a sentence to the API for annotation and returns the result.\n",
    "    Implements exponential backoff for 429 errors.\n",
    "    \"\"\"\n",
    "    payload = {\n",
    "        \"model\": \"meta-llama/Llama-3-8b-chat-hf\",  # Adjust model if needed\n",
    "        \"temperature\": 0.7,\n",
    "        \"frequency_penalty\": 0,\n",
    "        \"presence_penalty\": 0,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"Discard all the previous instructions. Behave\n",
    "                like you are an expert sentence classifier. Classify\n",
    "                the following sentence from FOMC into ‘Hawkish’, ‘Dovish’, or ‘Neutral’ class. Label\n",
    "                ‘Hawkish’ if it is corresponding to tightening of the monetary\n",
    "                policy, ‘Dovish’ if it is corresponding to easing of the monetary policy, or ‘Neutral’ if the stance is neutral.\n",
    "                No explanation needed.\n",
    "\n",
    "                1. Text sentiment: [Hawkish, Dovish, Neutral]\n",
    "                2. Time category: [Forward Looking or Backward Looking]\n",
    "                3. Certainty: [Certain or Uncertain]\n",
    "\n",
    "                Sentence: \"{sentence}\"\n",
    "\n",
    "                Provide your analysis in the following format:\n",
    "                Sentiment:\n",
    "                Time:\n",
    "                Certainty:\n",
    "                \"\"\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    max_retries = 5\n",
    "    retry_delay = 1  # Start with 1 second delay for retries\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.post(URL, json=payload, headers=headers)\n",
    "\n",
    "            # Handle 429 (Too Many Requests) with exponential backoff\n",
    "            if response.status_code == 429:\n",
    "                retry_after = int(response.headers.get(\"Retry-After\", retry_delay))\n",
    "                print(f\"Rate limit exceeded. Retrying in {retry_after} second(s)...\")\n",
    "                time.sleep(retry_after)  # Wait for the time suggested by the API or exponential delay\n",
    "                retry_delay *= 2  # Double the delay for each retry\n",
    "                continue  # Retry the request\n",
    "\n",
    "            # Raise exception for other HTTP errors\n",
    "            response.raise_for_status()\n",
    "\n",
    "            # Log the raw response to check if it's what you expect\n",
    "            result = response.json()\n",
    "            # print(f\"Raw API response: {result}\")  # DEBUG: Check the full response from the API\n",
    "\n",
    "            # Extract content from the 'message' field\n",
    "            message_content = result['choices'][0]['message']['content']\n",
    "            # print(f\"Message content: {message_content}\")  # DEBUG: Check the message content from the API\n",
    "\n",
    "            # Parse Sentiment\n",
    "            sentiment = None\n",
    "            if 'Sentiment:' in message_content:\n",
    "                sentiment = message_content.split('Sentiment:')[1].split('\\n')[0].strip()\n",
    "\n",
    "            # Parse Time\n",
    "            time_category = None\n",
    "            if 'Time:' in message_content:\n",
    "                time_category = message_content.split('Time:')[1].split('\\n')[0].strip()\n",
    "\n",
    "            # Parse Certainty\n",
    "            certainty = None\n",
    "            if 'Certainty:' in message_content:\n",
    "                certainty = message_content.split('Certainty:')[1].split('\\n')[0].strip()\n",
    "\n",
    "            # Map sentiment to 0, 1, or 2\n",
    "            # Why is dovish 0? Does not align with vocab order in the paper's prompt\n",
    "            parsed_annotation = None\n",
    "            if sentiment == \"Dovish\":\n",
    "                parsed_annotation = 0\n",
    "            elif sentiment == \"Hawkish\":\n",
    "                parsed_annotation = 1\n",
    "            elif sentiment == \"Neutral\":\n",
    "                parsed_annotation = 2\n",
    "\n",
    "            # Return the final result only if all necessary fields are present\n",
    "            if parsed_annotation is not None and time_category is not None and certainty is not None:\n",
    "                # print(f\"Parsed annotation: Sentiment={sentiment}, Time={time_category}, Certainty={certainty}\")  # DEBUG: Check parsed values\n",
    "                return {\n",
    "                    \"Sentence\": sentence,\n",
    "                    \"Sentiment\": sentiment,\n",
    "                    \"Time\": time_category,\n",
    "                    \"Certainty\": certainty,\n",
    "                    \"Parsed_Annotation\": parsed_annotation\n",
    "                }\n",
    "            else:\n",
    "                # print(f\"Missing fields for sentence: {sentence}\")  # DEBUG: Inform about missing fields\n",
    "                return {}  # Return empty if any field is missing or invalid\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error annotating sentence: {e}\")\n",
    "            return {\"Sentence\": sentence, \"Error\": str(e)}\n",
    "\n",
    "    print(f\"Max retries exceeded for sentence: {sentence}\")\n",
    "    return {\"Sentence\": sentence, \"Error\": \"Max retries exceeded\"}\n",
    "\n",
    "def process_sentences(data: List[Dict[str, str]]) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Processes the sentences by calling the API for each one and returning the results.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for item in data:\n",
    "        sentence = item['sentence']\n",
    "        label = item['label']\n",
    "        result = annotate_sentence(sentence)\n",
    "        if result and \"Parsed_Annotation\" in result:  # Skip if the sentence is considered hallucination\n",
    "            result['label'] = label  # Attach the ground truth label for comparison later\n",
    "            results.append(result)\n",
    "    return results\n",
    "\n",
    "def save_results(results: List[Dict[str, str]], output_file: str):\n",
    "    \"\"\"\n",
    "    Saves the results to a CSV file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.DictWriter(file, fieldnames=[\"Sentence\", \"Sentiment\", \"Time\", \"Certainty\", \"Parsed_Annotation\", \"label\"])\n",
    "            writer.writeheader()\n",
    "            writer.writerows(results)\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving results to {output_file}: {e}\")\n",
    "\n",
    "def evaluate_metrics(results: List[Dict[str, str]]):\n",
    "    \"\"\"\n",
    "    Evaluates the model performance using F1 Score, Precision, Recall, and Accuracy.\n",
    "    \"\"\"\n",
    "    y_true = []  # Ground truth labels from CSV\n",
    "    y_pred = []  # Model annotations (Parsed_Annotation)\n",
    "\n",
    "    for result in results:\n",
    "        y_true.append(result[\"label\"])  # Ground truth label\n",
    "        y_pred.append(result[\"Parsed_Annotation\"])  # Model's annotation\n",
    "\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    return f1, precision, recall, accuracy\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"/content/lab-manual-mm-test-5768.csv\"\n",
    "    output_file = \"annotated_sentences.csv\"\n",
    "\n",
    "    data = read_sentences_from_csv(input_file)  # Read sentences, years, and labels from CSV\n",
    "    annotated_results = process_sentences(data)  # Process sentences and get model annotations\n",
    "    save_results(annotated_results, output_file)  # Save the results with annotations and labels\n",
    "\n",
    "    # Evaluate the model's performance using the ground truth labels from CSV\n",
    "    evaluate_metrics(annotated_results)\n",
    "\n",
    "    print(f\"Annotation complete. Results saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9hK-MTIbI4vE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
